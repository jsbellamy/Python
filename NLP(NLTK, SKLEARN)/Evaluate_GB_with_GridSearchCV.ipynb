{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Machine Learning Classifiers: Evaluate Gradient Boosting with GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grid-search:** Exhaustively search all parameter combinations in a given grid to determine the best model.\n",
    "\n",
    "**Cross-validation:** Divide a dataset into k subsets and repeat the holdout method k times where a different subset is used as the holdout set in each iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_len</th>\n",
       "      <th>punct%</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>8094</th>\n",
       "      <th>8095</th>\n",
       "      <th>8096</th>\n",
       "      <th>8097</th>\n",
       "      <th>8098</th>\n",
       "      <th>8099</th>\n",
       "      <th>8100</th>\n",
       "      <th>8101</th>\n",
       "      <th>8102</th>\n",
       "      <th>8103</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>135</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   body_len  punct%  0  1  2  3  4  5  6  7  ...   8094  8095  8096  8097  \\\n",
       "0       128     4.7  0  0  0  0  0  0  0  0  ...      0     0     0     0   \n",
       "1        49     4.1  0  0  0  0  0  0  0  0  ...      0     0     0     0   \n",
       "2        62     3.2  0  0  0  0  0  0  0  0  ...      0     0     0     0   \n",
       "3        28     7.1  0  0  0  0  0  0  0  0  ...      0     0     0     0   \n",
       "4       135     4.4  0  0  0  0  0  0  0  0  ...      0     0     0     0   \n",
       "\n",
       "   8098  8099  8100  8101  8102  8103  \n",
       "0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0  \n",
       "2     0     0     0     0     0     0  \n",
       "3     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 8106 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import string\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "data = pd.read_csv(\"SMSSpamCollection.tsv\", sep='\\t')\n",
    "data.columns = ['label', 'body_text']\n",
    "\n",
    "def count_punct(text):\n",
    "    count = sum([1 for char in text if char in string.punctuation])\n",
    "    return round(count/(len(text) - text.count(\" \")), 3)*100\n",
    "\n",
    "data['body_len'] = data['body_text'].apply(lambda x: len(x) - x.count(\" \"))\n",
    "data['punct%'] = data['body_text'].apply(lambda x: count_punct(x))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopwords]\n",
    "    return text\n",
    "\n",
    "# TF-IDF\n",
    "tfidf_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "X_tfidf = tfidf_vect.fit_transform(data['body_text'])\n",
    "X_tfidf_feat = pd.concat([data['body_len'], data['punct%'], pd.DataFrame(X_tfidf.toarray())], axis=1)\n",
    "\n",
    "# CountVectorizer\n",
    "count_vect = CountVectorizer(analyzer=clean_text)\n",
    "X_count = count_vect.fit_transform(data['body_text'])\n",
    "X_count_feat = pd.concat([data['body_len'], data['punct%'], pd.DataFrame(X_count.toarray())], axis=1)\n",
    "\n",
    "X_count_feat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring parameter settings using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jake\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Jake\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Jake\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Jake\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Jake\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Jake\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Jake\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>294.388394</td>\n",
       "      <td>10.711122</td>\n",
       "      <td>0.293415</td>\n",
       "      <td>0.031294</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.965022</td>\n",
       "      <td>0.982031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.970002</td>\n",
       "      <td>0.006204</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>417.882346</td>\n",
       "      <td>4.278655</td>\n",
       "      <td>0.298321</td>\n",
       "      <td>0.046930</td>\n",
       "      <td>0.1</td>\n",
       "      <td>11</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 11, 'n_est...</td>\n",
       "      <td>0.965919</td>\n",
       "      <td>0.978437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.969643</td>\n",
       "      <td>0.004478</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>420.168261</td>\n",
       "      <td>66.142152</td>\n",
       "      <td>0.206665</td>\n",
       "      <td>0.033689</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 15, 'n_est...</td>\n",
       "      <td>0.965022</td>\n",
       "      <td>0.977538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.969463</td>\n",
       "      <td>0.004462</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>396.761140</td>\n",
       "      <td>17.451293</td>\n",
       "      <td>0.253323</td>\n",
       "      <td>0.029499</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 15, 'n_est...</td>\n",
       "      <td>0.964126</td>\n",
       "      <td>0.976640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.969104</td>\n",
       "      <td>0.004298</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>189.349064</td>\n",
       "      <td>6.485091</td>\n",
       "      <td>0.348771</td>\n",
       "      <td>0.044765</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.963229</td>\n",
       "      <td>0.976640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.967846</td>\n",
       "      <td>0.004721</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "1     294.388394     10.711122         0.293415        0.031294   \n",
       "3     417.882346      4.278655         0.298321        0.046930   \n",
       "5     420.168261     66.142152         0.206665        0.033689   \n",
       "4     396.761140     17.451293         0.253323        0.029499   \n",
       "0     189.349064      6.485091         0.348771        0.044765   \n",
       "\n",
       "  param_learning_rate param_max_depth param_n_estimators  \\\n",
       "1                 0.1               7                150   \n",
       "3                 0.1              11                150   \n",
       "5                 0.1              15                150   \n",
       "4                 0.1              15                100   \n",
       "0                 0.1               7                100   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "1  {'learning_rate': 0.1, 'max_depth': 7, 'n_esti...           0.965022   \n",
       "3  {'learning_rate': 0.1, 'max_depth': 11, 'n_est...           0.965919   \n",
       "5  {'learning_rate': 0.1, 'max_depth': 15, 'n_est...           0.965022   \n",
       "4  {'learning_rate': 0.1, 'max_depth': 15, 'n_est...           0.964126   \n",
       "0  {'learning_rate': 0.1, 'max_depth': 7, 'n_esti...           0.963229   \n",
       "\n",
       "   split1_test_score       ...         mean_test_score  std_test_score  \\\n",
       "1           0.982031       ...                0.970002        0.006204   \n",
       "3           0.978437       ...                0.969643        0.004478   \n",
       "5           0.977538       ...                0.969463        0.004462   \n",
       "4           0.976640       ...                0.969104        0.004298   \n",
       "0           0.976640       ...                0.967846        0.004721   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "1                1                 1.0                 1.0   \n",
       "3                2                 1.0                 1.0   \n",
       "5                3                 1.0                 1.0   \n",
       "4                4                 1.0                 1.0   \n",
       "0                5                 1.0                 1.0   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "1                 1.0                 1.0                 1.0   \n",
       "3                 1.0                 1.0                 1.0   \n",
       "5                 1.0                 1.0                 1.0   \n",
       "4                 1.0                 1.0                 1.0   \n",
       "0                 1.0                 1.0                 1.0   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "1               1.0              0.0  \n",
       "3               1.0              0.0  \n",
       "5               1.0              0.0  \n",
       "4               1.0              0.0  \n",
       "0               1.0              0.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "param = {\n",
    "    'n_estimators': [100, 150],\n",
    "    'max_depth': [7, 11, 15],\n",
    "    'learning_rate': [0.1]\n",
    "}\n",
    "gs = GridSearchCV(gb, param, cv=5, n_jobs=-1)\n",
    "cv_fit = gs.fit(X_tfidf_feat, data['label'])\n",
    "pd.DataFrame(cv_fit.cv_results_).sort_values('mean_test_score',ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "param = {\n",
    "    'n_estimators': [100, 150],\n",
    "    'max_depth': [7, 11, 15],\n",
    "    'learning_rate': [0.1]\n",
    "}\n",
    "gs = GridSearchCV(gb, param, cv=5, n_jobs=-1)\n",
    "cv_fit = gs.fit(X_count_feat, data['label'])\n",
    "pd.DataFrame(cv_fit.cv_results_).sort_values('mean_test_score',ascending=False)[0:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
